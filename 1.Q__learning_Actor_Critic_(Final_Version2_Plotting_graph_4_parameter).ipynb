{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "0sMGpLE4ku6D"
   },
   "outputs": [],
   "source": [
    "import numpy as np   #importing libraries\n",
    "import simpy \n",
    "import queue\n",
    "import sys\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from collections import deque\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import random\n",
    "import uuid\n",
    "import random as rd\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#rd.seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Pt4FrabOku6E"
   },
   "outputs": [],
   "source": [
    "global SZ,CP,RM\n",
    "SZ=[]\n",
    "CP=[]\n",
    "RM=[]\n",
    "N=15000\n",
    "k=10000\n",
    "C=5\n",
    "L=7\n",
    "state=[]\n",
    "#Lambda = 10\n",
    "#mu = 1.5\n",
    "alpha = 0.3\n",
    "gamma = 0.95\n",
    "#t = 0   #system clock\n",
    "t1=0\n",
    "t2=0\n",
    "t_lambda = 0 #poisson random variable used to generate next service time\n",
    "t_mu = 0  #poisson random variable used to generate next departure time\n",
    "t_a=0\n",
    "wait=0\n",
    "R=100\n",
    "\n",
    "transmission_time=0\n",
    "l=\"0\"\n",
    "P_transmission=500\n",
    "P_idle=100\n",
    "\n",
    "episodes = 10\n",
    "SHOW_EVERY = 100\n",
    "STATS_EVERY=100\n",
    "\n",
    "Q_dict=dict()\n",
    "\n",
    "action_list=()\n",
    "\n",
    "train_data=[]\n",
    "train_label=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "zQgLrn4bku6E"
   },
   "outputs": [],
   "source": [
    "class Packet(object):\n",
    "    def __init__(self, time, id, mobileID, seeed):\n",
    "        \n",
    "        self.time=time                                                \n",
    "        self.id=id\n",
    "        self.mobileID=mobileID   \n",
    "        self.size=random.randint(200,400) #seed 1 op 2, seed 2 op \n",
    "        SZ.append(round(self.size,2))\n",
    "        self.cpucycle=random.uniform(100,1900)\n",
    "        self.memory_need=random.uniform(1000,2000)\n",
    "        self.ram=random.randint(1, 32) #seed 1 op 3, seed 2 op 1, seed 3 op 4\n",
    "        RM.append(round(self.ram,2))\n",
    "\n",
    "class mobile(object): #mobile class with an ID              \n",
    "    def __init__(self, ID):\n",
    "        self.ID=ID\n",
    "        self.pot=int(1)\n",
    "        \n",
    "    #generates packets and sends via out_pipe\n",
    "    def packet_generator_initial(self, numPackets, env, out_pipe, task_id,send): \n",
    "        \n",
    "        yield env.timeout(send)\n",
    "        #print(\"sending task {} of mobile {} at time {}\".format(task_id, self.ID, env.now))\n",
    "        p=Packet(env.now, task_id, self.ID, self.pot)\n",
    "        self.pot+=1\n",
    "        if(self.pot==4):\n",
    "                self.pot=1\n",
    "        yield out_pipe.put(p)\n",
    "        \n",
    "    def packet_generator(self, numPackets, env, out_pipe, task_id,send,pipe4,currentpipe): \n",
    "        \n",
    "        yield env.timeout(send)\n",
    "        #print(\"sending task {} of mobile {} at time {}\".format(task_id, self.ID, env.now))\n",
    "        p=Packet(env.now, task_id, self.ID, self.pot)\n",
    "        self.pot+=1\n",
    "        if(self.pot==4):\n",
    "                self.pot=1\n",
    "        yield out_pipe.put(p)\n",
    "        \n",
    "        state=yield pipe4.get()\n",
    "        yield currentpipe.put(state)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ZhBzm9_tku6E"
   },
   "outputs": [],
   "source": [
    " def reward_generator(T,cpu,bw,m,cost):\n",
    "    cpuU=cpu*0.5\n",
    "    mU=m*0.5\n",
    "    bwU=bw*0.3\n",
    "    \n",
    "    cpusla=680\n",
    "    bwsla=301\n",
    "    msla=1000\n",
    "    Tsla1=1.5\n",
    "    Tsla2=3\n",
    "    \n",
    "    Ct1=0\n",
    "    ct2=0\n",
    "    Cp=0\n",
    "    Cbw=0\n",
    "    Cm=0\n",
    "    \n",
    "\n",
    "    \n",
    "    #if (G<Gsla):\n",
    "        #Cg=-5*(Gsla/G)\n",
    "    if (cpuU<cpusla):\n",
    "        Cp=-4* (cpusla/cpuU)\n",
    "    if (mU<msla):\n",
    "        Cm=-4* (msla/mU)\n",
    "    if (bwU<bwsla):\n",
    "        Cbw=-4* (bwsla/bwU)\n",
    "    if (T>Tsla1 and T<Tsla2):\n",
    "        Ct1 = -5 * (T/Tsla1)\n",
    "        rt=(Tsla1/T) + Ct1\n",
    "    elif (T>=Tsla2):\n",
    "        Ct2 = -6 * (T/Tsla1)\n",
    "        rt=(Tsla1/T) + Ct2\n",
    "    else:\n",
    "        rt=(Tsla1/T)\n",
    "        \n",
    "    if (cost==2):\n",
    "        costp=-6*cost\n",
    "    else:\n",
    "        costp=0\n",
    "    #if (N>Nsla):\n",
    "        #Cn=-5*(N/Nsla)\n",
    "    #if (cost>Cost_sla):\n",
    "        #Cost_n=-5*(cost/Cost_sla)\n",
    "    ru=(cpuU/cpusla)+Cp+(bwU/bwsla)+Cbw+(mU/msla)+Cm\n",
    "    Reward = rt + ru + costp  #Reward Function\n",
    "    return Reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "HCUOfDCHku6E"
   },
   "outputs": [],
   "source": [
    "class Fog(object):      \n",
    "    def __init__(self, ID):\n",
    "        self.ID=ID\n",
    "        self.cpuspeed=0\n",
    "        self.cpucycle=0\n",
    "        self.memory=0\n",
    "        self.R=0\n",
    "        self.Number_queue=0\n",
    "        self.lost=0\n",
    "        self.transmission_time=0\n",
    "        self.response_time=0\n",
    "        self.server_count=0\n",
    "        self.wait=0\n",
    "        self.taskinqueue=0\n",
    "        self.a=0\n",
    "        self.time=0\n",
    "        self.neighbour1=None\n",
    "        self.neighbour2=None\n",
    "        \n",
    "        self.service_time=[]\n",
    "        self.response_time_list=[]\n",
    "        self.response_time_list2=[]\n",
    "        self.Serverqueue=[]\n",
    "        self.taskinqueue1=[]\n",
    "        self.total_serverqueue=[]\n",
    "        self.waitlist=[]\n",
    "        self.energy_offloading=[]\n",
    "        self.reward_list=[]\n",
    "        self.state=[]\n",
    "        self.observation_space_discretesize = [11, 11, 2]\n",
    "        self.q_table = np.random.uniform(low=0, high=0, size=(self.observation_space_discretesize))\n",
    "    \n",
    "        \n",
    "    def Neighbour(self,neighbour1,neighbour2):\n",
    "        self.neighbour1=neighbour1\n",
    "        self.neighbour2=neighbour2\n",
    "\n",
    "    def Calculate_Q_value(self,prevoius_state,next_state,reward):\n",
    "\n",
    "      val=Q_dict.get(((prevoius_state[0],prevoius_state[1],prevoius_state[2],prevoius_state[3],prevoius_state[4],prevoius_state[5],prevoius_state[6],prevoius_state[7],prevoius_state[8],prevoius_state[9],prevoius_state[10],prevoius_state[11]),prevoius_state[12]),0.0)\n",
    "      nxt_val_1=Q_dict.get(((next_state[0],next_state[1],next_state[2],next_state[3],next_state[4],next_state[5],next_state[6],next_state[7],next_state[8],next_state[9],next_state[10],next_state[11]),0),0.0)\n",
    "      nxt_val_2=Q_dict.get(((next_state[0],next_state[1],next_state[2],next_state[3],next_state[4],next_state[5],next_state[6],next_state[7],next_state[8],next_state[9],next_state[10],next_state[11]),1),0.0)\n",
    "      nxt_val_3=Q_dict.get(((next_state[0],next_state[1],next_state[2],next_state[3],next_state[4],next_state[5],next_state[6],next_state[7],next_state[8],next_state[9],next_state[10],next_state[11]),2),0.0)\n",
    "     \n",
    "      nxt_val=max(nxt_val_1,nxt_val_2,nxt_val_3)\n",
    "        \n",
    "      target=reward+gamma*nxt_val\n",
    "      \n",
    "      Q_dict[((prevoius_state[0],prevoius_state[1],prevoius_state[2],prevoius_state[3],prevoius_state[4],prevoius_state[5],prevoius_state[6],prevoius_state[7],prevoius_state[8],prevoius_state[9],prevoius_state[10],prevoius_state[11]),prevoius_state[12])]=val+alpha*(target-val)\n",
    "      #Q_dict[((prevoius_state[0],prevoius_state[1],prevoius_state[2]),prevoius_state[3])]=val+alpha*(target-val)  \n",
    "    \n",
    "    def FOG(self, env, server, in_pipe,mobile,pipe4):\n",
    "        \n",
    "         msg = yield in_pipe.get()\n",
    "         self.cpuspeed=random.uniform(1000,1500)\n",
    "         self.memory=random.uniform(3000,4000)\n",
    "         #print(\"FOg\",self.ID,\"cPU\",self.cpuspeed)\n",
    "         self.R=random.uniform(900,1100)\n",
    "        \n",
    "         state.append([len(self.Serverqueue),len(self.neighbour1.Serverqueue),len(self.neighbour2.Serverqueue),self.cpuspeed,self.neighbour1.cpuspeed,self.neighbour2.cpuspeed,self.R,self.neighbour1.R,self.neighbour2.R,self.memory,self.neighbour1.memory,self.neighbour2.memory,self.ID,msg.id])   # CURRENT STATE for calaculatin Q VALU\n",
    "         #state.append([len(self.Serverqueue),len(self.neighbour1.Serverqueue),len(self.neighbour2.Serverqueue),self.ID,msg.id])  \n",
    "        \n",
    "         discrete_state=()\n",
    "         discrete_state=(self.taskinqueue,self.neighbour1.taskinqueue,self.neighbour2.taskinqueue,self.cpuspeed,self.neighbour1.cpuspeed,self.neighbour2.cpuspeed,self.R,self.neighbour1.R,self.neighbour2.R,self.memory,self.neighbour1.memory,self.neighbour2.memory)\n",
    "         #discrete_state=(self.taskinqueue,self.neighbour1.taskinqueue,self.neighbour2.taskinqueue)\n",
    "        \n",
    "         yield pipe4.put(discrete_state) # CURRENT STATE\n",
    "            \n",
    "         self.transmission_time = (msg.size/self.R)\n",
    "         #print(\"transmits task {} to need time {}\".format(msg.id,transmission_time,self.ID))\n",
    "         yield env.timeout(self.transmission_time)\n",
    "         a=env.now\n",
    "         #print(\"Arrived task {} at time {} at FOG {} from mobile {}\".format(msg.id,a,self.ID,mobile))\n",
    "         #print(\"server\",self.server_count)\n",
    "         #print(\"present q\",self.taskinqueue)\n",
    "\n",
    "         if self.server_count==C:\n",
    "            if len(self.Serverqueue)<k:\n",
    "               self.Serverqueue.append(msg)\n",
    "               self.taskinqueue=len(self.Serverqueue)\n",
    "               #print(\"queue te ase \",len(self.Serverqueue))\n",
    "               #print(\"task ase queue te ase \",taskinqueue)\n",
    "               self.Number_queue = self.Number_queue + 1\n",
    "               #self.server_count=0\n",
    "            else:\n",
    "                 self.lost=self.lost+1\n",
    "#                 cloud_transmission_time = (msg.size/R)\n",
    "#                 cloud_cpuspeed=random.uniform(2000,2500)\n",
    "#                 cloud_t_mu=msg.cpucycle/cloud_cpuspeed\n",
    "#                 self.service_time.append(cloud_t_mu)\n",
    "#                 #delay=random.uniform(3,6)\n",
    "#                 delay=5\n",
    "#                 self.response_time2=self.transmission_time+cloud_transmission_time+cloud_t_mu+delay\n",
    "#                 self.response_time_list2.append(self.response_time2)\n",
    "                \n",
    "                 cost=2\n",
    "                \n",
    "                 r=reward_generator(15,self.cpuspeed,self.R,self.memory,cost)\n",
    "                 self.reward_list.append(r)\n",
    "            \n",
    "                 new_state=[len(self.Serverqueue),len(self.neighbour1.Serverqueue),len(self.neighbour2.Serverqueue),self.cpuspeed,self.neighbour1.cpuspeed,self.neighbour2.cpuspeed,self.R,self.neighbour1.R,self.neighbour2.R,self.memory,self.neighbour1.memory,self.neighbour2.memory]\n",
    "                 #new_state=[len(self.Serverqueue),len(self.neighbour1.Serverqueue),len(self.neighbour2.Serverqueue)]\n",
    "            \n",
    "                 for i in state:\n",
    "                     if i[13]==msg.id:\n",
    "                     #if i[4]==msg.id:\n",
    "                         self.Calculate_Q_value(i,new_state,r)\n",
    "                         break\n",
    "\n",
    "                 return  \n",
    "\n",
    "         self.taskinqueue1.append(len(self.Serverqueue))\n",
    "\n",
    "         self.memory=self.memory-msg.memory_need   \n",
    "         t_mu=msg.cpucycle/self.cpuspeed\n",
    "         self.service_time.append(t_mu)\n",
    "         #print(t_mu)\n",
    "         \n",
    "         E = (P_transmission * self.transmission_time) + (P_idle * t_mu)\n",
    "         self.energy_offloading.append(E)\n",
    "         \n",
    "         #print(\"present a queue te ase \",len(self.Serverqueue))\n",
    "         #print(\"Fog:   Fog\",self.ID,\"mobile\",mobile,\", akhon queue te ase \",self.taskinqueue,\", time\",env.now)\n",
    "\n",
    "         with server.request() as req:\n",
    "             yield req\n",
    "             s=env.now\n",
    "             self.wait=s-a\n",
    "             if len(self.Serverqueue)>0:\n",
    "                 self.Serverqueue.pop(0)\n",
    "             #self.total_serverqueue.append(len(self.Serverqueue))\n",
    "             #print(\"queue\",len(self.Serverqueue))\n",
    "             #print(\"wait\",self.wait)\n",
    "             #print(\"Starting service task {} at time {} at FOG {}\".format(msg.id,s,self.ID))\n",
    "             #print(\"Waiting time of task {} at time {} at FOG {}\".format(msg.id,self.wait,self.ID))\n",
    "             self.waitlist.append(self.wait)\n",
    "             self.response_time=self.wait+t_mu+self.transmission_time\n",
    "             self.response_time_list.append(self.response_time)\n",
    "             \n",
    "             self.server_count=self.server_count+1\n",
    "             yield env.timeout(t_mu)\n",
    "             #print(\"Finish service task {} at time {} at FOG {}\".format(msg.id,env.now,self.ID))\n",
    "             self.server_count=self.server_count-1   \n",
    "            \n",
    "             cost=0\n",
    "             r=reward_generator(self.response_time,self.cpuspeed,self.R,self.memory,cost)\n",
    "             self.reward_list.append(r)\n",
    "             #print(\"r\",r)\n",
    "            \n",
    "             new_state=[len(self.Serverqueue),len(self.neighbour1.Serverqueue),len(self.neighbour2.Serverqueue),self.cpuspeed,self.neighbour1.cpuspeed,self.neighbour2.cpuspeed,self.R,self.neighbour1.R,self.neighbour2.R,self.memory,self.neighbour1.memory,self.neighbour2.memory]\n",
    "             #new_state=[len(self.Serverqueue),len(self.neighbour1.Serverqueue),len(self.neighbour2.Serverqueue)]\n",
    "            \n",
    "             for i in state:\n",
    "               if i[13]==msg.id:\n",
    "               #if i[4]==msg.id:\n",
    "                 self.Calculate_Q_value(i,new_state,r)\n",
    "                 break\n",
    "                \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "D_qAYjOzku6E"
   },
   "outputs": [],
   "source": [
    "class Decision(object):\n",
    "    def __init__(self, ID):\n",
    "        self.ID=ID\n",
    "        self.fog1_count=0\n",
    "        self.fog2_count=0\n",
    "        self.fog3_count=0\n",
    "        self.t1=0\n",
    "        self.t2=0\n",
    "        self.t3=0\n",
    "        self.t4=0\n",
    "        self.t5=0\n",
    "        self.t6=0\n",
    "        self.statetime=0\n",
    "        self.current=()\n",
    "    def decision(self,env1,Lambda,server1,server2,server3,pipe1,pipe2,pipe3,pipe4,pipe5,pipe6,pipe7,ms1,ms2,ms3,ms4,ms5,ms6,fog1,fog2,fog3,i,statepipe,currentpipe):\n",
    "        yield env1.timeout(0)\n",
    "\n",
    "        \n",
    "        #for j in range(10):\n",
    "        \n",
    "        if(i==0):\n",
    "                 self.fog1_count=self.fog1_count+1           \n",
    "                 u=rd.random()\n",
    "                 t_lambda=-np.log(u)/Lambda\n",
    "                 t_a=self.t1+t_lambda\n",
    "                 self.t1=t_a\n",
    "                 env1.process(ms1.packet_generator_initial(1, env1, pipe1, 0,t_a))\n",
    "                 env1.process(fog1.FOG(env1, server1, pipe1,ms1.ID,pipe4))\n",
    "                 #env1.process(fog1.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,0,statepipe))\n",
    "                    \n",
    "                \n",
    "        for j in range(1):\n",
    "            \n",
    "            u=rd.random()\n",
    "            t_lambda=-np.log(u)/Lambda\n",
    "            t_a=self.t1+t_lambda\n",
    "            self.t1=t_a\n",
    "            env1.process(ms1.packet_generator(1, env1, pipe1, i,t_a,pipe4,currentpipe))\n",
    "            \n",
    "            u=rd.random()\n",
    "            t_lambda=-np.log(u)/Lambda\n",
    "            t_a=self.t2+t_lambda\n",
    "            self.t2=t_a\n",
    "            env1.process(ms2.packet_generator(1, env1, pipe2, i,t_a,pipe4,currentpipe))\n",
    "            \n",
    "            u=rd.random()\n",
    "            t_lambda=-np.log(u)/Lambda\n",
    "            t_a=self.t3+t_lambda\n",
    "            self.t3=t_a\n",
    "            env1.process(ms3.packet_generator(1, env1, pipe3, i,t_a,pipe4,currentpipe))\n",
    "            \n",
    "#             u=rd.random()\n",
    "#             t_lambda=-np.log(u)/Lambda\n",
    "#             t_a=self.t4+t_lambda\n",
    "#             self.t4=t_a\n",
    "#             env1.process(ms4.packet_generator(1, env1, pipe5, i,t_a,pipe4,currentpipe))\n",
    "            \n",
    "#             u=rd.random()\n",
    "#             t_lambda=-np.log(u)/Lambda\n",
    "#             t_a=self.t5+t_lambda\n",
    "#             self.t5=t_a\n",
    "#             env1.process(ms5.packet_generator(1, env1, pipe6, i,t_a,pipe4,currentpipe))\n",
    "             \n",
    "#             u=rd.random()\n",
    "#             t_lambda=-np.log(u)/Lambda\n",
    "#             t_a=self.t6+t_lambda\n",
    "#             self.t6=t_a\n",
    "#             env1.process(ms6.packet_generator(1, env1, pipe7, i,t_a,pipe4,currentpipe))\n",
    "\n",
    "            current2=yield currentpipe.get()\n",
    "            #print(\"time, current state, i: \",env1.now,current2,i)\n",
    "            \n",
    "            action1=Q_dict.get((current2,0),0)\n",
    "            action2=Q_dict.get((current2,1),0)\n",
    "            action3=Q_dict.get((current2,2),0)\n",
    "            \n",
    "            action=np.argmax([action1,action2,action3])\n",
    "            if action==2:\n",
    "                action=np.random.choice([action,0,1],p=[0.8,0.1,0.1])\n",
    "            elif action==1:\n",
    "                action=np.random.choice([action,0,2],p=[0.8,0.1,0.1])\n",
    "            else:\n",
    "                action=np.random.choice([action,1,2],p=[0.8,0.1,0.1])  \n",
    "            \n",
    "            if(action==0):\n",
    "                    \n",
    "                            self.fog1_count=self.fog1_count+1\n",
    "                            env1.process(fog1.FOG(env1, server1, pipe1,ms1.ID,pipe4))\n",
    "                            #env1.process(fog1.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "#                             self.fog1_count=self.fog1_count+1\n",
    "#                             env1.process(fog1.FOG(env1, server1, pipe2,ms2.ID,pipe4))\n",
    "#                              #env1.process(fog1.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                            \n",
    "#                             self.fog1_count=self.fog1_count+1\n",
    "#                             env1.process(fog1.FOG(env1, server1, pipe3,ms3.ID,pipe4))\n",
    "                                                    \n",
    "                            \n",
    "            if(action==1):\n",
    "                             self.fog2_count=self.fog2_count+1\n",
    "                             env1.process(fog2.FOG(env1, server2, pipe1,ms1.ID,pipe4))\n",
    "                             #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe2,ms2.ID,pipe4))\n",
    "#                              #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                                \n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe3,ms3.ID,pipe4))\n",
    "\n",
    " \n",
    "            if(action==2):\n",
    "                             self.fog3_count=self.fog3_count+1\n",
    "                             env1.process(fog3.FOG(env1, server3, pipe1,ms1.ID,pipe4))\n",
    "                             #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe2,ms2.ID,pipe4))\n",
    "#                              #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))           \n",
    "                                \n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe3,ms3.ID,pipe4))\n",
    "\n",
    "####################################second mobile 333333333333333333333333\n",
    "\n",
    "            current2=yield currentpipe.get()\n",
    "            #print(\"time, current state, i: \",env1.now,current2,i)\n",
    "            \n",
    "            action1=Q_dict.get((current2,0),0)\n",
    "            action2=Q_dict.get((current2,1),0)\n",
    "            action3=Q_dict.get((current2,2),0)\n",
    "            \n",
    "            action=np.argmax([action1,action2,action3])\n",
    "            if action==2:\n",
    "                action=np.random.choice([action,0,1],p=[0.8,0.1,0.1])\n",
    "            elif action==1:\n",
    "                action=np.random.choice([action,0,2],p=[0.8,0.1,0.1])\n",
    "            else:\n",
    "                action=np.random.choice([action,1,2],p=[0.8,0.1,0.1])              \n",
    "            if(action==0):\n",
    "                    \n",
    "#                             self.fog1_count=self.fog1_count+1\n",
    "#                             env1.process(fog1.FOG(env1, server1, pipe1,ms1.ID,pipe4))\n",
    "#                             #env1.process(fog1.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "                             self.fog1_count=self.fog1_count+1\n",
    "                             env1.process(fog1.FOG(env1, server1, pipe2,ms2.ID,pipe4))\n",
    "                              #env1.process(fog1.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                            \n",
    "#                             self.fog1_count=self.fog1_count+1\n",
    "#                             env1.process(fog1.FOG(env1, server1, pipe3,ms3.ID,pipe4))\n",
    "                                                    \n",
    "                            \n",
    "            if(action==1):\n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe1,ms1.ID,pipe4))\n",
    "#                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "                             self.fog2_count=self.fog2_count+1\n",
    "                             env1.process(fog2.FOG(env1, server2, pipe2,ms2.ID,pipe4))\n",
    "                              #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                                \n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe3,ms3.ID,pipe4))\n",
    "\n",
    " \n",
    "            if(action==2):\n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe1,ms1.ID,pipe4))\n",
    "#                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "                             self.fog3_count=self.fog3_count+1\n",
    "                             env1.process(fog3.FOG(env1, server3, pipe2,ms2.ID,pipe4))\n",
    "                              #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))           \n",
    "                                \n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe3,ms3.ID,pipe4))\n",
    "\n",
    "####################################third mobile 333333333333333333333333\n",
    "\n",
    "            current2=yield currentpipe.get()\n",
    "            #print(\"time, current state, i: \",env1.now,current2,i)\n",
    "            \n",
    "            action1=Q_dict.get((current2,0),0)\n",
    "            action2=Q_dict.get((current2,1),0)\n",
    "            action3=Q_dict.get((current2,2),0)\n",
    "            \n",
    "            action=np.argmax([action1,action2,action3])\n",
    "            if action==2:\n",
    "                action=np.random.choice([action,0,1],p=[0.8,0.1,0.1])\n",
    "            elif action==1:\n",
    "                action=np.random.choice([action,0,2],p=[0.8,0.1,0.1])\n",
    "            else:\n",
    "                action=np.random.choice([action,1,2],p=[0.8,0.1,0.1])              \n",
    "            if(action==0):\n",
    "                    \n",
    "#                             self.fog1_count=self.fog1_count+1\n",
    "#                             env1.process(fog1.FOG(env1, server1, pipe1,ms1.ID,pipe4))\n",
    "#                             #env1.process(fog1.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "#                              self.fog1_count=self.fog1_count+1\n",
    "#                              env1.process(fog1.FOG(env1, server1, pipe2,ms2.ID,pipe4))\n",
    "#                               #env1.process(fog1.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                            \n",
    "                             self.fog1_count=self.fog1_count+1\n",
    "                             env1.process(fog1.FOG(env1, server1, pipe3,ms3.ID,pipe4))\n",
    "                                                    \n",
    "                            \n",
    "            if(action==1):\n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe1,ms1.ID,pipe4))\n",
    "#                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe2,ms2.ID,pipe4))\n",
    "#                               #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                                \n",
    "                             self.fog2_count=self.fog2_count+1\n",
    "                             env1.process(fog2.FOG(env1, server2, pipe3,ms3.ID,pipe4))\n",
    "\n",
    " \n",
    "            if(action==2):\n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe1,ms1.ID,pipe4))\n",
    "#                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe2,ms2.ID,pipe4))\n",
    "#                               #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))           \n",
    "                                \n",
    "                             self.fog3_count=self.fog3_count+1\n",
    "                             env1.process(fog3.FOG(env1, server3, pipe3,ms3.ID,pipe4))     \n",
    "\n",
    "#################################### fourth mobile 333333333333333333333333\n",
    "#             current2=yield currentpipe.get()\n",
    "#             #print(\"time, current state, i: \",env1.now,current2,i)\n",
    "            \n",
    "#             action1=Q_dict.get((current2,0))\n",
    "#             action2=Q_dict.get((current2,1))\n",
    "#             action3=Q_dict.get((current2,2))\n",
    "            \n",
    "#             if action1==None and action2==None and action3==None:\n",
    "#               action=random.randint(0,2)\n",
    "            \n",
    "#             elif action1!=None and action2==None and action3==None:\n",
    "#               action=0     \n",
    "#             elif action1==None and action2!=None and action3==None:\n",
    "#               action=1\n",
    "#             elif action1==None and action2==None and action3!=None:\n",
    "#               action=2\n",
    "            \n",
    "#             elif action1!=None and action2!=None and action3==None:\n",
    "#               if action1>action2:\n",
    "#                 action=0\n",
    "#               else:\n",
    "#                 action=1\n",
    "#             elif action1==None and action2!=None and action3!=None:\n",
    "#               if action2>action3:\n",
    "#                 action=1\n",
    "#               else:\n",
    "#                 action=2\n",
    "#             elif action1!=None and action2==None and action3!=None:\n",
    "#               if action1>action3:\n",
    "#                 action=0\n",
    "#               else:\n",
    "#                 action=2\n",
    "                \n",
    "#             elif action1!=None and action2!=None and action3!=None:\n",
    "#               if action1>action2 and action1>action3:\n",
    "#                 action=0\n",
    "#               if action2>action1 and action2>action3:\n",
    "#                 action=1\n",
    "#               if action3>action1 and action3>action2:\n",
    "#                 action=2\n",
    "#             elif action1==action2 or action2==action3 or action1==action3:\n",
    "#                 action=random.randint(0,2)\n",
    "            \n",
    "#             if(action==0):\n",
    "                    \n",
    "# #                             self.fog1_count=self.fog1_count+1\n",
    "# #                             env1.process(fog1.FOG(env1, server1, pipe1,ms1.ID,pipe4))\n",
    "# #                             #env1.process(fog1.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "# #                              self.fog1_count=self.fog1_count+1\n",
    "# #                              env1.process(fog1.FOG(env1, server1, pipe2,ms2.ID,pipe4))\n",
    "# #                               #env1.process(fog1.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                            \n",
    "#                              self.fog1_count=self.fog1_count+1\n",
    "#                              env1.process(fog1.FOG(env1, server1, pipe5,ms4.ID,pipe4))\n",
    "                                                    \n",
    "                            \n",
    "#             if(action==1):\n",
    "# #                              self.fog2_count=self.fog2_count+1\n",
    "# #                              env1.process(fog2.FOG(env1, server2, pipe1,ms1.ID,pipe4))\n",
    "# #                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "# #                              self.fog2_count=self.fog2_count+1\n",
    "# #                              env1.process(fog2.FOG(env1, server2, pipe2,ms2.ID,pipe4))\n",
    "# #                               #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                                \n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe5,ms4.ID,pipe4))\n",
    "\n",
    " \n",
    "#             if(action==2):\n",
    "# #                              self.fog3_count=self.fog3_count+1\n",
    "# #                              env1.process(fog3.FOG(env1, server3, pipe1,ms1.ID,pipe4))\n",
    "# #                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "# #                              self.fog3_count=self.fog3_count+1\n",
    "# #                              env1.process(fog3.FOG(env1, server3, pipe2,ms2.ID,pipe4))\n",
    "# #                               #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))           \n",
    "                                \n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe5,ms4.ID,pipe4))   \n",
    "            \n",
    "# #################################### fifth mobile 333333333333333333333333\n",
    "#             current2=yield currentpipe.get()\n",
    "#             #print(\"time, current state, i: \",env1.now,current2,i)\n",
    "            \n",
    "#             action1=Q_dict.get((current2,0))\n",
    "#             action2=Q_dict.get((current2,1))\n",
    "#             action3=Q_dict.get((current2,2))\n",
    "            \n",
    "#             if action1==None and action2==None and action3==None:\n",
    "#               action=random.randint(0,2)\n",
    "            \n",
    "#             elif action1!=None and action2==None and action3==None:\n",
    "#               action=0     \n",
    "#             elif action1==None and action2!=None and action3==None:\n",
    "#               action=1\n",
    "#             elif action1==None and action2==None and action3!=None:\n",
    "#               action=2\n",
    "            \n",
    "#             elif action1!=None and action2!=None and action3==None:\n",
    "#               if action1>action2:\n",
    "#                 action=0\n",
    "#               else:\n",
    "#                 action=1\n",
    "#             elif action1==None and action2!=None and action3!=None:\n",
    "#               if action2>action3:\n",
    "#                 action=1\n",
    "#               else:\n",
    "#                 action=2\n",
    "#             elif action1!=None and action2==None and action3!=None:\n",
    "#               if action1>action3:\n",
    "#                 action=0\n",
    "#               else:\n",
    "#                 action=2\n",
    "                \n",
    "#             elif action1!=None and action2!=None and action3!=None:\n",
    "#               if action1>action2 and action1>action3:\n",
    "#                 action=0\n",
    "#               if action2>action1 and action2>action3:\n",
    "#                 action=1\n",
    "#               if action3>action1 and action3>action2:\n",
    "#                 action=2\n",
    "#             elif action1==action2 or action2==action3 or action1==action3:\n",
    "#                 action=random.randint(0,2)\n",
    "            \n",
    "#             if(action==0):\n",
    "                    \n",
    "# #                             self.fog1_count=self.fog1_count+1\n",
    "# #                             env1.process(fog1.FOG(env1, server1, pipe1,ms1.ID,pipe4))\n",
    "# #                             #env1.process(fog1.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "# #                              self.fog1_count=self.fog1_count+1\n",
    "# #                              env1.process(fog1.FOG(env1, server1, pipe2,ms2.ID,pipe4))\n",
    "# #                               #env1.process(fog1.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                            \n",
    "#                              self.fog1_count=self.fog1_count+1\n",
    "#                              env1.process(fog1.FOG(env1, server1, pipe6,ms5.ID,pipe4))\n",
    "                                                    \n",
    "                            \n",
    "#             if(action==1):\n",
    "# #                              self.fog2_count=self.fog2_count+1\n",
    "# #                              env1.process(fog2.FOG(env1, server2, pipe1,ms1.ID,pipe4))\n",
    "# #                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "# #                              self.fog2_count=self.fog2_count+1\n",
    "# #                              env1.process(fog2.FOG(env1, server2, pipe2,ms2.ID,pipe4))\n",
    "# #                               #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                                \n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe6,ms5.ID,pipe4))\n",
    "\n",
    " \n",
    "#             if(action==2):\n",
    "# #                              self.fog3_count=self.fog3_count+1\n",
    "# #                              env1.process(fog3.FOG(env1, server3, pipe1,ms1.ID,pipe4))\n",
    "# #                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "# #                              self.fog3_count=self.fog3_count+1\n",
    "# #                              env1.process(fog3.FOG(env1, server3, pipe2,ms2.ID,pipe4))\n",
    "# #                               #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))           \n",
    "                                \n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe6,ms5.ID,pipe4))    \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "WGanD04pku6E",
    "outputId": "a7a04da5-ed60-4d34-cb3a-60fb194fae75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YO 1\n",
      "lost 13876 0 0\n",
      "present count 22173 4456 4496\n",
      "FOG-1 Average queueing time: 326.7482679808445\n",
      "FOG-1 Average service time: 0.7632992293346877\n",
      "MAX 1413.6852241123959\n",
      "FOG-1 Average response time: 327.81357894961644\n",
      "FOG-2 Average queueing time: 152.48279330490448\n",
      "FOG-2 Average service time: 0.84505790624812\n",
      "MAX 498.15786331374767\n",
      "FOG-2 Average response time: 153.60909613755524\n",
      "FOG-3 Average queueing time: 168.71965737669373\n",
      "FOG-3 Average service time: 0.8210576081938675\n",
      "FOG-3 Average response time: 169.8394313452025\n",
      "YO 2\n",
      "lost 13928 0 0\n",
      "present count 22157 4476 4440\n",
      "FOG-1 Average queueing time: 329.0620335163029\n",
      "FOG-1 Average service time: 0.7706212064370572\n",
      "MAX 1445.8891700096747\n",
      "FOG-1 Average response time: 330.13426660416116\n",
      "FOG-2 Average queueing time: 163.72505084541473\n",
      "FOG-2 Average service time: 0.8396554546980676\n",
      "MAX 505.8893717852575\n",
      "FOG-2 Average response time: 164.82256310874118\n",
      "FOG-3 Average queueing time: 188.42162401103855\n",
      "FOG-3 Average service time: 0.9183788904218002\n",
      "FOG-3 Average response time: 189.57637911850705\n",
      "YO 3\n",
      "lost 13848 0 0\n",
      "present count 22147 4456 4550\n",
      "FOG-1 Average queueing time: 321.4109187552436\n",
      "FOG-1 Average service time: 0.7598598741814871\n",
      "MAX 1395.0284959715045\n",
      "FOG-1 Average response time: 322.47178339557684\n",
      "FOG-2 Average queueing time: 157.03687743979955\n",
      "FOG-2 Average service time: 0.8063411196259793\n",
      "MAX 479.334511228091\n",
      "FOG-2 Average response time: 158.09970095697722\n",
      "FOG-3 Average queueing time: 155.8275276621931\n",
      "FOG-3 Average service time: 0.8094929044748337\n",
      "FOG-3 Average response time: 156.98283907393557\n",
      "YO 4\n",
      "lost 13844 0 0\n",
      "present count 22110 4495 4552\n",
      "FOG-1 Average queueing time: 341.7960708144421\n",
      "FOG-1 Average service time: 0.7786514559953095\n",
      "MAX 1488.4786789134557\n",
      "FOG-1 Average response time: 342.8752425373913\n",
      "FOG-2 Average queueing time: 149.00010712053182\n",
      "FOG-2 Average service time: 0.7541898138838244\n",
      "MAX 432.4988596878869\n",
      "FOG-2 Average response time: 150.03565352296204\n",
      "FOG-3 Average queueing time: 184.04139617589274\n",
      "FOG-3 Average service time: 0.8430234672401856\n",
      "FOG-3 Average response time: 185.25080697573534\n",
      "YO 5\n",
      "lost 13908 0 0\n",
      "present count 22108 4462 4523\n",
      "FOG-1 Average queueing time: 359.2454588827531\n",
      "FOG-1 Average service time: 0.820609478231532\n",
      "MAX 1660.413207605375\n",
      "FOG-1 Average response time: 360.3678766752413\n",
      "FOG-2 Average queueing time: 156.01332325986036\n",
      "FOG-2 Average service time: 0.840666519636376\n",
      "MAX 505.6398837708126\n",
      "FOG-2 Average response time: 157.10800362521235\n",
      "FOG-3 Average queueing time: 177.3091512015141\n",
      "FOG-3 Average service time: 0.8252318908867599\n",
      "FOG-3 Average response time: 178.45096276162093\n",
      "YO 6\n",
      "lost 13857 0 0\n",
      "present count 22201 4367 4576\n",
      "FOG-1 Average queueing time: 343.02000657152615\n",
      "FOG-1 Average service time: 0.7850569188385597\n",
      "MAX 1507.0153610983461\n",
      "FOG-1 Average response time: 344.10714882768644\n",
      "FOG-2 Average queueing time: 140.1506674349972\n",
      "FOG-2 Average service time: 0.775864308034834\n",
      "MAX 440.0287928749277\n",
      "FOG-2 Average response time: 141.20448634390155\n",
      "FOG-3 Average queueing time: 185.0583016460713\n",
      "FOG-3 Average service time: 0.8658425685239572\n",
      "FOG-3 Average response time: 186.17209887306961\n"
     ]
    }
   ],
   "source": [
    "avg_response_time=[]\n",
    "avg_energy=[]\n",
    "avgqlength=[]\n",
    "avg_reward=[]\n",
    "max_reward=[]\n",
    "rrt=[]\n",
    "random_energy=[]\n",
    "leng=[]\n",
    "rwd=[]\n",
    "\n",
    "for Lambda in range(1,L):\n",
    "    env1 = simpy.Environment()    \n",
    "    server1 = simpy.Resource(env1, capacity=C)\n",
    "    server2 = simpy.Resource(env1, capacity=C)\n",
    "    server3 = simpy.Resource(env1, capacity=C)\n",
    "    rd.seed(2)\n",
    "\n",
    "    pipe1 = simpy.Store(env1)\n",
    "    pipe2 = simpy.Store(env1)\n",
    "    pipe3 = simpy.Store(env1)\n",
    "    pipe4 = simpy.Store(env1)\n",
    "    pipe5 = simpy.Store(env1)\n",
    "    pipe6 = simpy.Store(env1)\n",
    "    pipe7 = simpy.Store(env1)\n",
    "    \n",
    "    statepipe = simpy.Store(env1)\n",
    "    currentpipe = simpy.Store(env1)\n",
    "\n",
    "    ms1=mobile(1)\n",
    "    ms2=mobile(2)\n",
    "    ms3=mobile(3)\n",
    "    ms4=mobile(4)\n",
    "    ms5=mobile(5)\n",
    "    ms6=mobile(6)\n",
    "    \n",
    "\n",
    "    fog1 = Fog(0)\n",
    "    fog2 = Fog(1)\n",
    "    fog3=Fog(2)\n",
    "\n",
    "    fog1.Neighbour(fog2,fog3)\n",
    "    fog2.Neighbour(fog1,fog3)\n",
    "    fog3.Neighbour(fog1,fog2)\n",
    "    \n",
    "\n",
    "    obj=Decision(1)\n",
    "    #Lambda=10\n",
    "    print(\"YO\",Lambda)\n",
    "    for i in range(N):\n",
    "        env1.process(obj.decision(env1,Lambda,server1,server2,server3,pipe1,pipe2,pipe3,pipe4,pipe5,pipe6,pipe7,ms1,ms2,ms3,ms4,ms5,ms6,fog1,fog2,fog3,i,statepipe,currentpipe))\n",
    "    env1.run()\n",
    "\n",
    "    #print(\"after simulation q_table\",q_table)\n",
    "    #print(\"after simulation present state and action\",action_list)\n",
    "\n",
    "    fog1_count=obj.fog1_count\n",
    "    fog2_count=obj.fog2_count\n",
    "    fog3_count=obj.fog3_count\n",
    "    fog1_count=fog1_count-fog1.lost\n",
    "    fog2_count=fog2_count-fog2.lost\n",
    "    fog3_count=fog3_count-fog3.lost\n",
    "\n",
    "    if(Lambda==6):\n",
    "        \n",
    "        with open('Q_learning_fog1_iteration_time.txt', 'w') as f:\n",
    "            for item in fog1.response_time_list:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "        with open('Q_learning_fog1_iteration_reward.txt', 'w') as f:\n",
    "            for item in fog1.reward_list:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "        with open('Q_learning_fog1_iteration_queue.txt', 'w') as f:\n",
    "            for item in fog1.taskinqueue1:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "                \n",
    "        with open('Q_learning_fog2_iteration_time.txt', 'w') as f:\n",
    "            for item in fog2.response_time_list:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "        with open('Q_learning_fog2_iteration_reward.txt', 'w') as f:\n",
    "            for item in fog2.reward_list:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "        with open('Q_learning_fog2_iteration_queue.txt', 'w') as f:\n",
    "            for item in fog2.taskinqueue1:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "                \n",
    "        with open('Q_learning_fog3_iteration_time.txt', 'w') as f:\n",
    "            for item in fog3.response_time_list:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "        with open('Q_learning_fog3_iteration_reward.txt', 'w') as f:\n",
    "            for item in fog3.reward_list:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "        with open('Q_learning_fog3_iteration_queue.txt', 'w') as f:\n",
    "            for item in fog3.taskinqueue1:\n",
    "                f.write(\"%s\\n\" % item)\n",
    "\n",
    "    print(\"lost\",fog1.lost,fog2.lost,fog3.lost)\n",
    "    print(\"present count\",fog1_count,fog2_count,fog3_count)\n",
    "    avgwaittime=sum(fog1.waitlist)/fog1_count\n",
    "    print(\"FOG-1 Average queueing time:\", avgwaittime)\n",
    "    avgservicetime=sum(fog1.service_time)/fog1_count\n",
    "    print(\"FOG-1 Average service time:\", avgservicetime)\n",
    "    avgsystemtime1=sum(fog1.response_time_list)/fog1_count\n",
    "    print(\"MAX\",max(fog1.response_time_list))\n",
    "    print(\"FOG-1 Average response time:\", avgsystemtime1)\n",
    "    avgenergy1=sum(fog1.energy_offloading)/fog1_count\n",
    "    #print(\"FOG-1 Average Energy consumption:\", avgenergy1)\n",
    "    avgqlength1=sum(fog1.taskinqueue1)/fog1_count\n",
    "    avgreward1=sum(fog1.reward_list)/fog1_count\n",
    "    maxreward1=max(fog1.reward_list)\n",
    "    \n",
    "    max_reward.append(maxreward1)\n",
    "    avg_reward.append(avgreward1)\n",
    "    avgqlength.append(avgqlength1)\n",
    "    avg_response_time.append(avgsystemtime1)\n",
    "    avg_energy.append(avgenergy1)\n",
    "    \n",
    "    avgwaittime=sum(fog2.waitlist)/fog2_count\n",
    "    print(\"FOG-2 Average queueing time:\", avgwaittime)\n",
    "    avgservicetime=sum(fog2.service_time)/fog2_count\n",
    "    print(\"FOG-2 Average service time:\", avgservicetime)\n",
    "    avgsystemtime2=sum(fog2.response_time_list)/fog2_count\n",
    "    print(\"MAX\",max(fog2.response_time_list))\n",
    "    print(\"FOG-2 Average response time:\", avgsystemtime2)\n",
    "    avgenergy2=sum(fog2.energy_offloading)/fog2_count\n",
    "    #print(\"FOG-2 Average Energy consumption:\", avgenergy2)\n",
    "    avgqlength2=sum(fog2.taskinqueue1)/fog2_count\n",
    "    avgreward2=sum(fog2.reward_list)/fog2_count\n",
    "    maxreward2=max(fog2.reward_list)\n",
    "    \n",
    "    max_reward.append(maxreward2)\n",
    "    avg_reward.append(avgreward2)\n",
    "    avgqlength.append(avgqlength2)\n",
    "    avg_response_time.append(avgsystemtime2)\n",
    "    avg_energy.append(avgenergy2)\n",
    "\n",
    "    avgwaittime=sum(fog3.waitlist)/fog3_count\n",
    "    print(\"FOG-3 Average queueing time:\", avgwaittime)\n",
    "    avgservicetime=sum(fog3.service_time)/fog3_count\n",
    "    print(\"FOG-3 Average service time:\", avgservicetime)\n",
    "    avgsystemtime3=sum(fog3.response_time_list)/fog3_count\n",
    "    print(\"FOG-3 Average response time:\", avgsystemtime3)\n",
    "    avgenergy3=sum(fog3.energy_offloading)/fog3_count\n",
    "    avgqlength3=sum(fog3.taskinqueue1)/fog3_count\n",
    "    avgreward3=sum(fog3.reward_list)/fog3_count\n",
    "    maxreward3=max(fog3.reward_list)\n",
    "    \n",
    "    max_reward.append(maxreward3)\n",
    "    avg_reward.append(avgreward3)  \n",
    "    avgqlength.append(avgqlength3)\n",
    "    avg_response_time.append(avgsystemtime3)\n",
    "    avg_energy.append(avgenergy3)\n",
    "\n",
    "\n",
    "s=0\n",
    "l=0\n",
    "l1=0\n",
    "m=(L-1)*3\n",
    "\n",
    "for i in range(0,m,3):\n",
    "    s=(avg_response_time[i]+avg_response_time[i+1]+avg_response_time[i+2])/3\n",
    "    s=round(s,3)\n",
    "    rrt.append(s)\n",
    "    l=(avgqlength[i]+avgqlength[i+1]+avgqlength[i+2])/3\n",
    "    l=round(l,3)\n",
    "    leng.append(l)\n",
    "    l1=(avg_reward[i]+avg_reward[i+1]+avg_reward[i+2])/3\n",
    "    l1=round(l1,3)\n",
    "    rwd.append(l1)\n",
    "\n",
    "# with open('Q_learning_time_k10000.txt', 'w') as f:\n",
    "#     for item in rrt:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "\n",
    "# with open('Q_learning_avg_response_time_k10000.txt', 'w') as f:\n",
    "#     for item in avg_response_time:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "        \n",
    "# with open('Q_learning_qlength_k10000.txt', 'w') as f:\n",
    "#     for item in leng:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "\n",
    "# with open('Q_learning_avgreward_k10000.txt', 'w') as f:\n",
    "#     for item in rwd:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "\n",
    "# with open('Q_learning_maxreward_k10000.txt', 'w') as f:\n",
    "#     for item in max_reward:\n",
    "#         f.write(\"%s\\n\" % item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACTOR CRITIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fZS_aCxhku6G"
   },
   "outputs": [],
   "source": [
    "class ActorCriticNetwork(keras.Model):\n",
    "    def __init__(self,n_actions,fc1_dims=32,fc2_dims=32):\n",
    "        super(ActorCriticNetwork,self).__init__()\n",
    "        self.fc1_dims=fc1_dims\n",
    "        self.fc2_dims=fc2_dims\n",
    "        self.n_actions=n_actions\n",
    "        \n",
    "        \n",
    "        self.fc1=Dense(self.fc1_dims,activation='relu')\n",
    "        self.fc2=Dense(self.fc2_dims,activation='relu')\n",
    "        self.v=Dense(1,activation='linear')\n",
    "        self.pi=Dense(n_actions,activation='softmax')\n",
    "        \n",
    "    def call(self,state):\n",
    "        value=self.fc1(state)\n",
    "        value=self.fc2(value)\n",
    "        \n",
    "        v=self.v(value)\n",
    "        pi=self.pi(value)\n",
    "        \n",
    "        return v,pi\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self,alpha=0.0003,gamma=0.99,n_actions=2):\n",
    "        self.gamma=gamma\n",
    "        self.n_actions=n_actions\n",
    "        self.action=None\n",
    "        self.action_space=[i for i in range(self.n_actions)]\n",
    "        \n",
    "        self.actor_critic=ActorCriticNetwork(n_actions=n_actions)\n",
    "        self.actor_critic.compile(optimizer=Adam(learning_rate=alpha))\n",
    "        \n",
    "    def choose_action(self,observation):\n",
    "        state=tf.convert_to_tensor([observation])\n",
    "        _,probs=self.actor_critic(state)\n",
    "        \n",
    "        action_probabilities=tfp.distributions.Categorical(probs=probs)\n",
    "        action=action_probabilities.sample()\n",
    "        self.action=action\n",
    "        return action.numpy()[0]\n",
    "    \n",
    "    def learn(self,state,reward,state_,done):\n",
    "        state=tf.convert_to_tensor([state],dtype=tf.float32)\n",
    "        state_=tf.convert_to_tensor([state_],dtype=tf.float32)\n",
    "        reward=tf.convert_to_tensor(reward,dtype=tf.float32)\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            state_value,probs=self.actor_critic(state)\n",
    "            state_value_,_=self.actor_critic(state_)\n",
    "            state_value=tf.squeeze(state_value)\n",
    "            state_value_=tf.squeeze(state_value_)\n",
    "            \n",
    "            action_probs=tfp.distributions.Categorical(probs=probs)\n",
    "            log_prob=action_probs.log_prob(self.action)\n",
    "            \n",
    "            delta=reward+self.gamma*state_value_*(1-int(done))-state_value\n",
    "            actor_loss=-(log_prob*delta)\n",
    "            critic_loss=delta**2\n",
    "            \n",
    "            total_loss=actor_loss + critic_loss\n",
    "            \n",
    "        gradient=tape.gradient(total_loss,self.actor_critic.trainable_variables)\n",
    "        self.actor_critic.optimizer.apply_gradients(zip(gradient,self.actor_critic.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fog(object):      \n",
    "    def __init__(self, ID):\n",
    "        self.ID=ID\n",
    "        self.cpuspeed=0\n",
    "        self.cpucycle=0\n",
    "        self.memory=0\n",
    "        self.R=0\n",
    "        self.Number_queue=0\n",
    "        self.lost=0\n",
    "        self.transmission_time=0\n",
    "        self.response_time=0\n",
    "        self.server_count=0\n",
    "        self.wait=0\n",
    "        self.taskinqueue=0\n",
    "        self.a=0\n",
    "        self.time=0\n",
    "        self.neighbour1=None\n",
    "        self.neighbour2=None\n",
    "        \n",
    "        self.service_time=[]\n",
    "        self.response_time_list=[]\n",
    "        self.response_time_list2=[]\n",
    "        self.Serverqueue=[]\n",
    "        self.taskinqueue1=[]\n",
    "        self.total_serverqueue=[]\n",
    "        self.waitlist=[]\n",
    "        self.energy_offloading=[]\n",
    "        self.reward_list=[]\n",
    "        self.state=[]\n",
    "        self.observation_space_discretesize = [11, 11, 2]\n",
    "        self.q_table = np.random.uniform(low=0, high=0, size=(self.observation_space_discretesize))\n",
    "    \n",
    "        \n",
    "    def Neighbour(self,neighbour1,neighbour2):\n",
    "        self.neighbour1=neighbour1\n",
    "        self.neighbour2=neighbour2\n",
    "\n",
    "    def Calculate_Q_value(self,prevoius_state,next_state,reward):\n",
    "\n",
    "      val=Q_dict.get(((prevoius_state[0],prevoius_state[1],prevoius_state[2],prevoius_state[3],prevoius_state[4],prevoius_state[5],prevoius_state[6],prevoius_state[7],prevoius_state[8],prevoius_state[9],prevoius_state[10],prevoius_state[11]),prevoius_state[12]))\n",
    "      nxt_val_1=Q_dict.get(((next_state[0],next_state[1],next_state[2],next_state[3],next_state[4],next_state[5],next_state[6],next_state[7],next_state[8],next_state[9],next_state[10],next_state[11]),0))\n",
    "      nxt_val_2=Q_dict.get(((next_state[0],next_state[1],next_state[2],next_state[3],next_state[4],next_state[5],next_state[6],next_state[7],next_state[8],next_state[9],next_state[10],next_state[11]),1))\n",
    "      nxt_val_3=Q_dict.get(((next_state[0],next_state[1],next_state[2],next_state[3],next_state[4],next_state[5],next_state[6],next_state[7],next_state[8],next_state[9],next_state[10],next_state[11]),2))\n",
    "    \n",
    "#       val=Q_dict.get(((prevoius_state[0],prevoius_state[1],prevoius_state[2]),prevoius_state[3]))\n",
    "#       nxt_val_1=Q_dict.get(((next_state[0],next_state[1],next_state[2]),0))\n",
    "#       nxt_val_2=Q_dict.get(((next_state[0],next_state[1],next_state[2]),1))\n",
    "#       nxt_val_3=Q_dict.get(((next_state[0],next_state[1],next_state[2]),2))\n",
    "        \n",
    "      \n",
    "      if nxt_val_1==None and nxt_val_2==None and nxt_val_3==None:\n",
    "          nxt_val=0\n",
    "      elif nxt_val_1==None and nxt_val_2==None and nxt_val_3!=None:\n",
    "          nxt_val=nxt_val_3\n",
    "      elif nxt_val_1==None and nxt_val_2!=None and nxt_val_3==None:\n",
    "          nxt_val=nxt_val_2\n",
    "      elif nxt_val_1!=None and nxt_val_2==None and nxt_val_3==None:\n",
    "          nxt_val=nxt_val_1\n",
    "      elif nxt_val_1!=None and nxt_val_2!=None and nxt_val_3==None:\n",
    "          if nxt_val_1>=nxt_val_2:\n",
    "              nxt_val=nxt_val_1\n",
    "          else:\n",
    "              nxt_val=nxt_val_2\n",
    "      elif nxt_val_1==None and nxt_val_2!=None and nxt_val_3!=None:\n",
    "          if nxt_val_2>=nxt_val_3:\n",
    "              nxt_val=nxt_val_2\n",
    "          else:\n",
    "              nxt_val=nxt_val_3\n",
    "      elif nxt_val_1!=None and nxt_val_2==None and nxt_val_3!=None:\n",
    "          if nxt_val_1>=nxt_val_3:\n",
    "              nxt_val=nxt_val_1\n",
    "          else:\n",
    "              nxt_val=nxt_val_3\n",
    "      elif nxt_val_1!=None and nxt_val_2!=None and nxt_val_3!=None:\n",
    "          if nxt_val_1>=nxt_val_2 and nxt_val_1>=nxt_val_3:\n",
    "              nxt_val=nxt_val_1\n",
    "          elif nxt_val_2>nxt_val_1 and nxt_val_2>=nxt_val_3:\n",
    "              nxt_val=nxt_val_2\n",
    "          elif nxt_val_3>nxt_val_1 and nxt_val_3>nxt_val_2:\n",
    "              nxt_val=nxt_val_3\n",
    "      \n",
    "      if val==None:\n",
    "          val=0\n",
    "     \n",
    "                      \n",
    "      target=reward+gamma*nxt_val\n",
    "      \n",
    "      Q_dict[((prevoius_state[0],prevoius_state[1],prevoius_state[2],prevoius_state[3],prevoius_state[4],prevoius_state[5],prevoius_state[6],prevoius_state[7],prevoius_state[8],prevoius_state[9],prevoius_state[10],prevoius_state[11]),prevoius_state[12])]=val+alpha*(target-val)\n",
    "      #Q_dict[((prevoius_state[0],prevoius_state[1],prevoius_state[2]),prevoius_state[3])]=val+alpha*(target-val)  \n",
    "    \n",
    "    def FOG(self, env, server, in_pipe,mobile,pipe4,agent):\n",
    "        \n",
    "         msg = yield in_pipe.get()\n",
    "         self.cpuspeed=random.uniform(1000,1500)\n",
    "         self.memory=random.uniform(3000,4000)\n",
    "         #print(\"FOg\",self.ID,\"cPU\",self.cpuspeed)\n",
    "         self.R=random.uniform(900,1100)\n",
    "        \n",
    "         state.append([(len(self.Serverqueue)/10),len(self.neighbour1.Serverqueue)/10,len(self.neighbour2.Serverqueue)/10,(self.cpuspeed-1000)/500,(self.neighbour1.cpuspeed-1000)/500,(self.neighbour2.cpuspeed-1000)/500,(self.R-900)/200,(self.neighbour1.R-900)/200,(self.neighbour2.R-900)/200,(self.memory-3000)/1000,(self.neighbour1.memory-3000)/1000,(self.neighbour2.memory-3000)/1000,self.ID,msg.id])   # CURRENT STATE for calaculatin Q VALU\n",
    "         #state.append([len(self.Serverqueue),len(self.neighbour1.Serverqueue),len(self.neighbour2.Serverqueue),self.ID,msg.id])  \n",
    "        \n",
    "         discrete_state=()\n",
    "         discrete_state=(self.taskinqueue,self.neighbour1.taskinqueue,self.neighbour2.taskinqueue,self.cpuspeed,self.neighbour1.cpuspeed,self.neighbour2.cpuspeed,self.R,self.neighbour1.R,self.neighbour2.R,self.memory,self.neighbour1.memory,self.neighbour2.memory)\n",
    "         #discrete_state=(self.taskinqueue,self.neighbour1.taskinqueue,self.neighbour2.taskinqueue)\n",
    "        \n",
    "         yield pipe4.put(discrete_state) # CURRENT STATE\n",
    "            \n",
    "         self.transmission_time = (msg.size/self.R)\n",
    "         #print(\"transmits task {} to need time {}\".format(msg.id,transmission_time,self.ID))\n",
    "         yield env.timeout(self.transmission_time)\n",
    "         a=env.now\n",
    "         #print(\"Arrived task {} at time {} at FOG {} from mobile {}\".format(msg.id,a,self.ID,mobile))\n",
    "         #print(\"server\",self.server_count)\n",
    "         #print(\"present q\",self.taskinqueue)\n",
    "\n",
    "         if self.server_count==C:\n",
    "            if len(self.Serverqueue)<k:\n",
    "               self.Serverqueue.append(msg)\n",
    "               self.taskinqueue=len(self.Serverqueue)\n",
    "               #print(\"queue te ase \",len(self.Serverqueue))\n",
    "               #print(\"task ase queue te ase \",taskinqueue)\n",
    "               self.Number_queue = self.Number_queue + 1\n",
    "               #self.server_count=0\n",
    "            else:\n",
    "                 self.lost=self.lost+1\n",
    "#                 cloud_transmission_time = (msg.size/R)\n",
    "#                 cloud_cpuspeed=random.uniform(2000,2500)\n",
    "#                 cloud_t_mu=msg.cpucycle/cloud_cpuspeed\n",
    "#                 self.service_time.append(cloud_t_mu)\n",
    "#                 #delay=random.uniform(3,6)\n",
    "#                 delay=5\n",
    "#                 self.response_time2=self.transmission_time+cloud_transmission_time+cloud_t_mu+delay\n",
    "#                 self.response_time_list2.append(self.response_time2)\n",
    "                \n",
    "                 cost=2\n",
    "                \n",
    "                 r=reward_generator(15,self.cpuspeed,self.R,self.memory,cost)\n",
    "                 self.reward_list.append(r)\n",
    "            \n",
    "                 new_state=[(len(self.Serverqueue)/10),len(self.neighbour1.Serverqueue)/10,len(self.neighbour2.Serverqueue)/10,(self.cpuspeed-1000)/500,(self.neighbour1.cpuspeed-1000)/500,(self.neighbour2.cpuspeed-1000)/500,(self.R-900)/200,(self.neighbour1.R-900)/200,(self.neighbour2.R-900)/200,(self.memory-3000)/1000,(self.neighbour1.memory-3000)/1000,(self.neighbour2.memory-3000)/1000]\n",
    "                 #new_state=[len(self.Serverqueue),len(self.neighbour1.Serverqueue),len(self.neighbour2.Serverqueue)]\n",
    "            \n",
    "                 for i in state:\n",
    "                     if i[13]==msg.id:\n",
    "                     #if i[4]==msg.id:\n",
    "                        s=i[0:len(i)-2]\n",
    "                        agent.learn(s,r,new_state,False)\n",
    "#                         agent.remember(s,i[len(i)-2],r,new_state,False)\n",
    "#                         if len(agent.memory)>=16:\n",
    "#                             if cnt%20==0:\n",
    "#                                 agent.update_target_network()\n",
    "#                             agent.replay(16)\n",
    "                        # print(len(agent.memory))\n",
    "                        #  self.Calculate_Q_value(i,new_state,r)\n",
    "                        break\n",
    "\n",
    "                 return  \n",
    "\n",
    "         self.taskinqueue1.append(len(self.Serverqueue))\n",
    "        \n",
    "         self.memory=self.memory-msg.memory_need   \n",
    "         t_mu=msg.cpucycle/self.cpuspeed\n",
    "         self.service_time.append(t_mu)\n",
    "         #print(t_mu)\n",
    "         \n",
    "         E = (P_transmission * self.transmission_time) + (P_idle * t_mu)\n",
    "         self.energy_offloading.append(E)\n",
    "         \n",
    "         #print(\"present a queue te ase \",len(self.Serverqueue))\n",
    "         #print(\"Fog:   Fog\",self.ID,\"mobile\",mobile,\", akhon queue te ase \",self.taskinqueue,\", time\",env.now)\n",
    "\n",
    "         with server.request() as req:\n",
    "             yield req\n",
    "             s=env.now\n",
    "             self.wait=s-a\n",
    "             if len(self.Serverqueue)>0:\n",
    "                 self.Serverqueue.pop(0)\n",
    "             #self.total_serverqueue.append(len(self.Serverqueue))\n",
    "             #print(\"queue\",len(self.Serverqueue))\n",
    "             #print(\"wait\",self.wait)\n",
    "             #print(\"Starting service task {} at time {} at FOG {}\".format(msg.id,s,self.ID))\n",
    "             #print(\"Waiting time of task {} at time {} at FOG {}\".format(msg.id,self.wait,self.ID))\n",
    "             self.waitlist.append(self.wait)\n",
    "             self.response_time=self.wait+t_mu+self.transmission_time\n",
    "             self.response_time_list.append(self.response_time)\n",
    "             \n",
    "             self.server_count=self.server_count+1\n",
    "             yield env.timeout(t_mu)\n",
    "             #print(\"Finish service task {} at time {} at FOG {}\".format(msg.id,env.now,self.ID))\n",
    "             self.server_count=self.server_count-1   \n",
    "            \n",
    "             cost=0\n",
    "             r=reward_generator(self.response_time,self.cpuspeed,self.R,self.memory,cost)\n",
    "             self.reward_list.append(r)\n",
    "             #print(\"r\",r)\n",
    "            \n",
    "             new_state=[(len(self.Serverqueue)/10),len(self.neighbour1.Serverqueue)/10,len(self.neighbour2.Serverqueue)/10,(self.cpuspeed-1000)/500,(self.neighbour1.cpuspeed-1000)/500,(self.neighbour2.cpuspeed-1000)/500,(self.R-900)/200,(self.neighbour1.R-900)/200,(self.neighbour2.R-900)/200,(self.memory-3000)/1000,(self.neighbour1.memory-3000)/1000,(self.neighbour2.memory-3000)/1000]\n",
    "             #new_state=[len(self.Serverqueue),len(self.neighbour1.Serverqueue),len(self.neighbour2.Serverqueue)]\n",
    "            \n",
    "             for i in state:\n",
    "                     if i[13]==msg.id:\n",
    "                     #if i[4]==msg.id:\n",
    "                        s=i[0:len(i)-2]\n",
    "                        agent.learn(s,r,new_state,False)\n",
    "#                         agent.remember(s,i[len(i)-2],r,new_state,False)\n",
    "#                         if len(agent.memory)>=16:\n",
    "#                             if cnt%20==0:\n",
    "#                                 agent.update_target_network()\n",
    "#                             agent.replay(16)\n",
    "                        # print(len(agent.memory))\n",
    "                        #  self.Calculate_Q_value(i,new_state,r)\n",
    "                        break\n",
    "                \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "mXCSJ9vzku6G"
   },
   "outputs": [],
   "source": [
    "class Decision(object):\n",
    "    def __init__(self, ID):\n",
    "        self.ID=ID\n",
    "        self.fog1_count=0\n",
    "        self.fog2_count=0\n",
    "        self.fog3_count=0\n",
    "        self.t1=0\n",
    "        self.t2=0\n",
    "        self.t3=0\n",
    "        self.t4=0\n",
    "        self.t5=0\n",
    "        self.t6=0\n",
    "        self.statetime=0\n",
    "        self.current=()\n",
    "    def decision1(self,env1,Lambda,server1,server2,server3,pipe1,pipe2,pipe3,pipe4,pipe5,pipe6,pipe7,ms1,ms2,ms3,ms4,ms5,ms6,fog1,fog2,fog3,i,statepipe,currentpipe,agent):\n",
    "        yield env1.timeout(0)\n",
    "\n",
    "        \n",
    "        #for j in range(10):\n",
    "        \n",
    "        if(i==0):\n",
    "                 self.fog1_count=self.fog1_count+1           \n",
    "                 u=rd.random()\n",
    "                 t_lambda=-np.log(u)/Lambda\n",
    "                 t_a=self.t1+t_lambda\n",
    "                 self.t1=t_a\n",
    "                 env1.process(ms1.packet_generator_initial(1, env1, pipe1, 0,t_a))\n",
    "                 env1.process(fog1.FOG(env1, server1, pipe1,ms1.ID,pipe4,agent))\n",
    "                 #env1.process(fog1.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,0,statepipe))\n",
    "                    \n",
    "                \n",
    "        for j in range(1):\n",
    "            \n",
    "            u=rd.random()\n",
    "            t_lambda=-np.log(u)/Lambda\n",
    "            t_a=self.t1+t_lambda\n",
    "            self.t1=t_a\n",
    "            env1.process(ms1.packet_generator(1, env1, pipe1, i,t_a,pipe4,currentpipe))\n",
    "            \n",
    "            u=rd.random()\n",
    "            t_lambda=-np.log(u)/Lambda\n",
    "            t_a=self.t2+t_lambda\n",
    "            self.t2=t_a\n",
    "            env1.process(ms2.packet_generator(1, env1, pipe2, i,t_a,pipe4,currentpipe))\n",
    "            \n",
    "            u=rd.random()\n",
    "            t_lambda=-np.log(u)/Lambda\n",
    "            t_a=self.t3+t_lambda\n",
    "            self.t3=t_a\n",
    "            env1.process(ms3.packet_generator(1, env1, pipe3, i,t_a,pipe4,currentpipe))\n",
    "            \n",
    "            u=rd.random()\n",
    "            t_lambda=-np.log(u)/Lambda\n",
    "            t_a=self.t4+t_lambda\n",
    "            self.t4=t_a\n",
    "            env1.process(ms4.packet_generator(1, env1, pipe5, i,t_a,pipe4,currentpipe))\n",
    "            \n",
    "            u=rd.random()\n",
    "            t_lambda=-np.log(u)/Lambda\n",
    "            t_a=self.t5+t_lambda\n",
    "            self.t5=t_a\n",
    "            env1.process(ms5.packet_generator(1, env1, pipe6, i,t_a,pipe4,currentpipe))\n",
    "                         \n",
    "#             u=rd.random()\n",
    "#             t_lambda=-np.log(u)/Lambda\n",
    "#             t_a=self.t6+t_lambda\n",
    "#             self.t6=t_a\n",
    "#             env1.process(ms6.packet_generator(1, env1, pipe7, i,t_a,pipe4,currentpipe))\n",
    "\n",
    "            current2=yield currentpipe.get()\n",
    "            acstate=[current2[0],current2[1],current2[2],current2[3],current2[4],current2[5],current2[6],current2[7],current2[8],current2[9],current2[10],current2[11]]\n",
    "            action=agent.choose_action(acstate)\n",
    "            if action==2:\n",
    "                action=np.random.choice([action,0,1],p=[0.9,0.05,0.05])\n",
    "            elif action==1:\n",
    "                action=np.random.choice([action,0,2],p=[0.9,0.05,0.05])\n",
    "            else:\n",
    "                action=np.random.choice([action,1,2],p=[0.9,0.05,0.05])\n",
    "            if(action==0):\n",
    "                    \n",
    "                            self.fog1_count=self.fog1_count+1\n",
    "                            env1.process(fog1.FOG(env1, server1, pipe1,ms1.ID,pipe4,agent))\n",
    "                            #env1.process(fog1.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "#                             self.fog1_count=self.fog1_count+1\n",
    "#                             env1.process(fog1.FOG(env1, server1, pipe2,ms2.ID,pipe4))\n",
    "#                             #env1.process(fog1.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                            \n",
    "#                             self.fog1_count=self.fog1_count+1\n",
    "#                             env1.process(fog1.FOG(env1, server1, pipe3,ms3.ID,pipe4))\n",
    "                            \n",
    "#                             self.fog1_count=self.fog1_count+1\n",
    "#                             env1.process(fog1.FOG(env1, server1, pipe5,ms4.ID,pipe4))\n",
    "                            \n",
    "#                             self.fog1_count=self.fog1_count+1\n",
    "#                             env1.process(fog1.FOG(env1, server1, pipe6,ms5.ID,pipe4))\n",
    "                            \n",
    "#                             self.fog1_count=self.fog1_count+1\n",
    "#                             env1.process(fog1.FOG(env1, server1, pipe7,ms6.ID,pipe4))\n",
    "                            \n",
    "            if(action==1):\n",
    "                             self.fog2_count=self.fog2_count+1\n",
    "                             env1.process(fog2.FOG(env1, server2, pipe1,ms1.ID,pipe4,agent))\n",
    "                             #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe2,ms2.ID,pipe4))\n",
    "#                              #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                                \n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe3,ms3.ID,pipe4))\n",
    "                                \n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe5,ms4.ID,pipe4))\n",
    "                                \n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe6,ms5.ID,pipe4))\n",
    "                                \n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe7,ms6.ID,pipe4))\n",
    " \n",
    "            if(action==2):\n",
    "                             self.fog3_count=self.fog3_count+1\n",
    "                             env1.process(fog3.FOG(env1, server3, pipe1,ms1.ID,pipe4,agent))\n",
    "                             #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe2,ms2.ID,pipe4))\n",
    "#                              #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))           \n",
    "                               \n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe3,ms3.ID,pipe4))\n",
    "\n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe5,ms4.ID,pipe4))\n",
    "                            \n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe6,ms5.ID,pipe4))\n",
    "                            \n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe7,ms6.ID,pipe4))\n",
    "                            \n",
    "####################################second mobile 333333333333333333333333\n",
    "            current2=yield currentpipe.get()\n",
    "            acstate=[current2[0],current2[1],current2[2],current2[3],current2[4],current2[5],current2[6],current2[7],current2[8],current2[9],current2[10],current2[11]]\n",
    "            action=agent.choose_action(acstate)\n",
    "            if action==2:\n",
    "                action=np.random.choice([action,0,1],p=[0.9,0.05,0.05])\n",
    "            elif action==1:\n",
    "                action=np.random.choice([action,0,2],p=[0.9,0.05,0.05])\n",
    "            else:\n",
    "                action=np.random.choice([action,1,2],p=[0.9,0.05,0.05])\n",
    "            if(action==0):\n",
    "                    \n",
    "#                             self.fog1_count=self.fog1_count+1\n",
    "#                             env1.process(fog1.FOG(env1, server1, pipe1,ms1.ID,pipe4))\n",
    "#                             #env1.process(fog1.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "                             self.fog1_count=self.fog1_count+1\n",
    "                             env1.process(fog1.FOG(env1, server1, pipe2,ms2.ID,pipe4,agent))\n",
    "                              #env1.process(fog1.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                            \n",
    "#                             self.fog1_count=self.fog1_count+1\n",
    "#                             env1.process(fog1.FOG(env1, server1, pipe3,ms3.ID,pipe4))\n",
    "                                                    \n",
    "                            \n",
    "            if(action==1):\n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe1,ms1.ID,pipe4))\n",
    "#                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "                             self.fog2_count=self.fog2_count+1\n",
    "                             env1.process(fog2.FOG(env1, server2, pipe2,ms2.ID,pipe4,agent))\n",
    "                              #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                                \n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe3,ms3.ID,pipe4))\n",
    "\n",
    " \n",
    "            if(action==2):\n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe1,ms1.ID,pipe4))\n",
    "#                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "                             self.fog3_count=self.fog3_count+1\n",
    "                             env1.process(fog3.FOG(env1, server3, pipe2,ms2.ID,pipe4,agent))\n",
    "                              #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))           \n",
    "                                \n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe3,ms3.ID,pipe4))\n",
    "\n",
    "####################################third mobile 333333333333333333333333\n",
    "            current2=yield currentpipe.get()\n",
    "            acstate=[current2[0],current2[1],current2[2],current2[3],current2[4],current2[5],current2[6],current2[7],current2[8],current2[9],current2[10],current2[11]]\n",
    "            action=agent.choose_action(acstate)\n",
    "            if action==2:\n",
    "                action=np.random.choice([action,0,1],p=[0.9,0.05,0.05])\n",
    "            elif action==1:\n",
    "                action=np.random.choice([action,0,2],p=[0.9,0.05,0.05])\n",
    "            else:\n",
    "                action=np.random.choice([action,1,2],p=[0.9,0.05,0.05])\n",
    "            if(action==0):\n",
    "                    \n",
    "#                             self.fog1_count=self.fog1_count+1\n",
    "#                             env1.process(fog1.FOG(env1, server1, pipe1,ms1.ID,pipe4))\n",
    "#                             #env1.process(fog1.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "#                              self.fog1_count=self.fog1_count+1\n",
    "#                              env1.process(fog1.FOG(env1, server1, pipe2,ms2.ID,pipe4))\n",
    "#                               #env1.process(fog1.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                            \n",
    "                             self.fog1_count=self.fog1_count+1\n",
    "                             env1.process(fog1.FOG(env1, server1, pipe3,ms3.ID,pipe4,agent))\n",
    "                                                    \n",
    "                            \n",
    "            if(action==1):\n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe1,ms1.ID,pipe4))\n",
    "#                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe2,ms2.ID,pipe4))\n",
    "#                               #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                                \n",
    "                             self.fog2_count=self.fog2_count+1\n",
    "                             env1.process(fog2.FOG(env1, server2, pipe3,ms3.ID,pipe4,agent))\n",
    "\n",
    " \n",
    "            if(action==2):\n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe1,ms1.ID,pipe4))\n",
    "#                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe2,ms2.ID,pipe4))\n",
    "#                               #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))           \n",
    "                                \n",
    "                             self.fog3_count=self.fog3_count+1\n",
    "                             env1.process(fog3.FOG(env1, server3, pipe3,ms3.ID,pipe4,agent)) \n",
    "            \n",
    "#################################### fourth mobile 333333333333333333333333\n",
    "       \n",
    "#             current2=yield currentpipe.get()\n",
    "#             dqnstate=[current2[0],current2[1],current2[2],current2[3],current2[4],current2[5],current2[6],current2[7],current2[8],current2[9],current2[10],current2[11]]\n",
    "#             action=agent.act(dqnstate)   \n",
    "#             if(action==0):\n",
    "                    \n",
    "# #                             self.fog1_count=self.fog1_count+1\n",
    "# #                             env1.process(fog1.FOG(env1, server1, pipe1,ms1.ID,pipe4))\n",
    "# #                             #env1.process(fog1.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "# #                              self.fog1_count=self.fog1_count+1\n",
    "# #                              env1.process(fog1.FOG(env1, server1, pipe2,ms2.ID,pipe4))\n",
    "# #                               #env1.process(fog1.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                            \n",
    "#                              self.fog1_count=self.fog1_count+1\n",
    "#                              env1.process(fog1.FOG(env1, server1, pipe5,ms4.ID,pipe4,agent))\n",
    "                                                    \n",
    "                            \n",
    "#             if(action==1):\n",
    "# #                              self.fog2_count=self.fog2_count+1\n",
    "# #                              env1.process(fog2.FOG(env1, server2, pipe1,ms1.ID,pipe4))\n",
    "# #                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "# #                              self.fog2_count=self.fog2_count+1\n",
    "# #                              env1.process(fog2.FOG(env1, server2, pipe2,ms2.ID,pipe4))\n",
    "# #                               #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                                \n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe5,ms4.ID,pipe4,agent))\n",
    "\n",
    " \n",
    "#             if(action==2):\n",
    "# #                              self.fog3_count=self.fog3_count+1\n",
    "# #                              env1.process(fog3.FOG(env1, server3, pipe1,ms1.ID,pipe4))\n",
    "# #                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "# #                              self.fog3_count=self.fog3_count+1\n",
    "# #                              env1.process(fog3.FOG(env1, server3, pipe2,ms2.ID,pipe4))\n",
    "# #                               #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))           \n",
    "                                \n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe5,ms4.ID,pipe4,agent))  \n",
    "# #################################### fifth mobile 333333333333333333333333\n",
    "\n",
    "#             current2=yield currentpipe.get()\n",
    "#             dqnstate=[current2[0],current2[1],current2[2],current2[3],current2[4],current2[5],current2[6],current2[7],current2[8],current2[9],current2[10],current2[11]]\n",
    "#             action=agent.act(dqnstate)    \n",
    "            \n",
    "#             if(action==0):\n",
    "                    \n",
    "# #                             self.fog1_count=self.fog1_count+1\n",
    "# #                             env1.process(fog1.FOG(env1, server1, pipe1,ms1.ID,pipe4))\n",
    "# #                             #env1.process(fog1.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "# #                              self.fog1_count=self.fog1_count+1\n",
    "# #                              env1.process(fog1.FOG(env1, server1, pipe2,ms2.ID,pipe4))\n",
    "# #                               #env1.process(fog1.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                            \n",
    "#                              self.fog1_count=self.fog1_count+1\n",
    "#                              env1.process(fog1.FOG(env1, server1, pipe6,ms5.ID,pipe4,agent))\n",
    "                                                    \n",
    "                            \n",
    "#             if(action==1):\n",
    "# #                              self.fog2_count=self.fog2_count+1\n",
    "# #                              env1.process(fog2.FOG(env1, server2, pipe1,ms1.ID,pipe4))\n",
    "# #                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "# #                              self.fog2_count=self.fog2_count+1\n",
    "# #                              env1.process(fog2.FOG(env1, server2, pipe2,ms2.ID,pipe4))\n",
    "# #                               #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "                                \n",
    "#                              self.fog2_count=self.fog2_count+1\n",
    "#                              env1.process(fog2.FOG(env1, server2, pipe6,ms5.ID,pipe4,agent))\n",
    "\n",
    " \n",
    "#             if(action==2):\n",
    "# #                              self.fog3_count=self.fog3_count+1\n",
    "# #                              env1.process(fog3.FOG(env1, server3, pipe1,ms1.ID,pipe4))\n",
    "# #                              #env1.process(fog2.nextstate(env1,ms1.ID,pipe3,pipe4,rewardpipe,action,statepipe))\n",
    "\n",
    "# #                              self.fog3_count=self.fog3_count+1\n",
    "# #                              env1.process(fog3.FOG(env1, server3, pipe2,ms2.ID,pipe4))\n",
    "# #                               #env1.process(fog2.nextstate(env1,ms2.ID,pipe3,pipe4,rewardpipe,action,statepipe))           \n",
    "                                \n",
    "#                              self.fog3_count=self.fog3_count+1\n",
    "#                              env1.process(fog3.FOG(env1, server3, pipe6,ms5.ID,pipe4,agent))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MNF25ccmku6G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YO 1\n",
      "YO 2\n",
      "YO 3\n",
      "YO 4\n",
      "YO 5\n",
      "YO 6\n",
      "YO 7\n",
      "YO 8\n",
      "YO 9\n",
      "YO 10\n",
      "YO 11\n"
     ]
    }
   ],
   "source": [
    "avg_response_time2=[]\n",
    "avg_energy2=[]\n",
    "agent=Agent(alpha=0.000025,gamma=0.95,n_actions=3)\n",
    "rrt2=[]\n",
    "random_energy2=[]\n",
    "avgqlength2=[]\n",
    "avg_reward2=[]\n",
    "max_reward2=[]\n",
    "leng2=[]\n",
    "rwd2=[]\n",
    "\n",
    "Q_dict=dict()\n",
    "\n",
    "for Lambda in range(1,L):\n",
    "    env1 = simpy.Environment()    \n",
    "    server1 = simpy.Resource(env1, capacity=C)\n",
    "    server2 = simpy.Resource(env1, capacity=C)\n",
    "    server3 = simpy.Resource(env1, capacity=C)\n",
    "    rd.seed(2)\n",
    "\n",
    "    pipe1 = simpy.Store(env1)\n",
    "    pipe2 = simpy.Store(env1)\n",
    "    pipe3 = simpy.Store(env1)\n",
    "    pipe4 = simpy.Store(env1)\n",
    "    pipe5 = simpy.Store(env1)\n",
    "    pipe6 = simpy.Store(env1)\n",
    "    pipe7 = simpy.Store(env1)\n",
    "    statepipe = simpy.Store(env1)\n",
    "    currentpipe = simpy.Store(env1)\n",
    "\n",
    "    ms1=mobile(1)\n",
    "    ms2=mobile(2)\n",
    "    ms3=mobile(3)\n",
    "    ms4=mobile(4)\n",
    "    ms5=mobile(5)\n",
    "    ms6=mobile(6)\n",
    "\n",
    "    fog1 = Fog(0)\n",
    "    fog2 = Fog(1)\n",
    "    fog3=Fog(2)\n",
    "\n",
    "    fog1.Neighbour(fog2,fog3)\n",
    "    fog2.Neighbour(fog1,fog3)\n",
    "    fog3.Neighbour(fog1,fog2)\n",
    "    \n",
    "\n",
    "    obj=Decision(1)\n",
    "    #Lambda=10\n",
    "    print(\"YO\",Lambda)\n",
    "    for i in range(N):\n",
    "        env1.process(obj.decision1(env1,Lambda,server1,server2,server3,pipe1,pipe2,pipe3,pipe4,pipe5,pipe6,pipe7,ms1,ms2,ms3,ms4,ms5,ms6,fog1,fog2,fog3,i,statepipe,currentpipe,agent))\n",
    "    env1.run()\n",
    "\n",
    "    #print(\"after simulation q_table\",q_table)\n",
    "    #print(\"after simulation present state and action\",action_list)\n",
    "\n",
    "    fog1_count=obj.fog1_count\n",
    "    fog2_count=obj.fog2_count\n",
    "    fog3_count=obj.fog3_count\n",
    "    fog1_count=fog1_count-fog1.lost\n",
    "    fog2_count=fog2_count-fog2.lost\n",
    "    fog3_count=fog3_count-fog3.lost\n",
    "\n",
    "    #print(\"lost\",fog1.lost,fog2.lost,fog3.lost)\n",
    "    #print(\"present count\",fog1_count,fog2_count,fog3_count)\n",
    "    avgwaittime=sum(fog1.waitlist)/fog1_count\n",
    "    #print(\"FOG-1 Average queueing time:\", avgwaittime)\n",
    "    avgservicetime=sum(fog1.service_time)/fog1_count\n",
    "    #print(\"FOG-1 Average service time:\", avgservicetime)\n",
    "    avgsystemtime1=sum(fog1.response_time_list)/fog1_count\n",
    "    #print(\"FOG-1 Average response time:\", avgsystemtime1)\n",
    "    avgenergy1=sum(fog1.energy_offloading)/fog1_count\n",
    "    #print(\"FOG-1 Average Energy consumption:\", avgenergy1)\n",
    "    avgqulength1=sum(fog1.taskinqueue1)/fog1_count\n",
    "    avgreward1=sum(fog1.reward_list)/fog1_count\n",
    "    maxreward1=max(fog1.reward_list)\n",
    "    \n",
    "    max_reward2.append(maxreward1)\n",
    "    avg_reward2.append(avgreward1) \n",
    "    avgqlength2.append(avgqulength1)\n",
    "    avg_response_time2.append(avgsystemtime1)\n",
    "    avg_energy2.append(avgenergy1)\n",
    "    \n",
    "\n",
    "    avgwaittime=sum(fog2.waitlist)/fog2_count\n",
    "    #print(\"FOG-2 Average queueing time:\", avgwaittime)\n",
    "    avgservicetime=sum(fog2.service_time)/fog2_count\n",
    "    #print(\"FOG-2 Average service time:\", avgservicetime)\n",
    "    avgsystemtime2=sum(fog2.response_time_list)/fog2_count\n",
    "    #print(\"FOG-2 Average response time:\", avgsystemtime2)\n",
    "    avgenergy2=sum(fog2.energy_offloading)/fog2_count\n",
    "    #print(\"FOG-2 Average Energy consumption:\", avgenergy2)\n",
    "    avgqulength2=sum(fog2.taskinqueue1)/fog2_count\n",
    "    avgreward2=sum(fog2.reward_list)/fog2_count\n",
    "    maxreward2=max(fog2.reward_list)\n",
    "    \n",
    "    max_reward2.append(maxreward2)\n",
    "    avg_reward2.append(avgreward2) \n",
    "    avgqlength2.append(avgqulength2)\n",
    "    avg_response_time2.append(avgsystemtime2)\n",
    "    avg_energy2.append(avgenergy2)\n",
    "\n",
    "    avgwaittime=sum(fog3.waitlist)/fog3_count\n",
    "    #print(\"FOG-3 Average queueing time:\", avgwaittime)\n",
    "    avgservicetime=sum(fog3.service_time)/fog3_count\n",
    "    #print(\"FOG-3 Average service time:\", avgservicetime)\n",
    "    avgsystemtime3=sum(fog3.response_time_list)/fog3_count\n",
    "    #print(\"FOG-3 Average response time:\", avgsystemtime3)\n",
    "    avgenergy3=sum(fog3.energy_offloading)/fog3_count\n",
    "    avgqulength3=sum(fog3.taskinqueue1)/fog3_count\n",
    "    avgreward3=sum(fog3.reward_list)/fog3_count\n",
    "    maxreward3=max(fog3.reward_list)\n",
    "    \n",
    "    max_reward2.append(maxreward3)\n",
    "    avg_reward2.append(avgreward3) \n",
    "    avgqlength2.append(avgqulength3) \n",
    "    avg_response_time2.append(avgsystemtime3)\n",
    "    avg_energy2.append(avgenergy3)\n",
    "\n",
    "s=0\n",
    "l=0\n",
    "l1=0\n",
    "m=(L-1)*3\n",
    "\n",
    "for i in range(0,m,3):\n",
    "    s=(avg_response_time2[i]+avg_response_time2[i+1]+avg_response_time2[i+2])/3\n",
    "    s=round(s,3)\n",
    "    rrt2.append(s)\n",
    "    l=(avgqlength2[i]+avgqlength2[i+1]+avgqlength2[i+2])/3\n",
    "    l=round(l,3)\n",
    "    leng2.append(l)\n",
    "    l1=(avg_reward2[i]+avg_reward2[i+1]+avg_reward2[i+2])/3\n",
    "    l1=round(l1,3)\n",
    "    rwd2.append(l1)\n",
    "    \n",
    "with open('Actor_Critic_time_k10000.txt', 'w') as f:\n",
    "    for item in rrt2:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "with open('Actor_Critic_avg_response_time_k10000.txt', 'w') as f:\n",
    "    for item in avg_response_time2:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "with open('Actor_Critic_qlength_k10000.txt', 'w') as f:\n",
    "    for item in leng2:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "with open('Actor_Critic_avgreward_k10000.txt', 'w') as f:\n",
    "    for item in rwd2:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "        \n",
    "with open('Actor_Critic_maxreward_k10000.txt', 'w') as f:\n",
    "    for item in max_reward2:\n",
    "        f.write(\"%s\\n\" % item)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "gpnhnMMDku6G",
    "outputId": "23ac9af4-fa2a-44c7-fd6b-8e69751f6ccc"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rrt=[478.281,\n",
    "499.313,\n",
    "508.412,\n",
    "529.095,\n",
    "515.369,\n",
    "521.521,\n",
    "541.22,\n",
    "614.722,\n",
    "687.741,\n",
    "736.158,\n",
    "763.017\n",
    "]\n",
    "\n",
    "# with open(\"Q_learning_time.txt\") as file:\n",
    "#     for line in file: \n",
    "#         line = line.strip() #or some other preprocessing\n",
    "#         rrt.append(line) #storing everything in memory!\n",
    "\n",
    "# print(rrt)\n",
    "# print(rrt2)\n",
    "\n",
    "\n",
    "lamda1=[1,2,3,4,5,6,7,8,9,10,11] # 10,11,12 bad\n",
    "lamda2=[1,2,3,4,5,6,7,8,9,10,11]\n",
    "\n",
    "\n",
    "time1=[ rrt[0],rrt[1],rrt[2],rrt[3],rrt[4],rrt[5],rrt[6],rrt[7],rrt[8],rrt[9],rrt[10] ]\n",
    "time2=[ rrt2[0],rrt2[1],rrt2[2],rrt2[3],rrt2[4],rrt2[5],rrt2[6],rrt2[7],rrt2[8],rrt2[9],rrt2[10] ]\n",
    "\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,10)\n",
    "\n",
    "l1=plt.plot(lamda1,time1,linewidth=2,color='red',linestyle='dashed',label='Q-learning')\n",
    "l2=plt.plot(lamda2,time2,linewidth=2,color='blue',label='Actor-Critic')\n",
    "\n",
    "#plt.yticks([1,1.25,1.5,1.75,2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.25])\n",
    "#plt.yticks([1,1.5,2,2.5,3,3.5,4,5])\n",
    "#plt.yticks([1,2,3,4,5,6])\n",
    "#plt.yticks([1,1.10,1.20,1.30,1.40,1.50,1.60,1.70,1.80,1.90,2,2.10,2.20,2.30,2.40,2.50,2.60,2.70,2.80,2.90,3,3.10,3.20,3.30,3.40,3.50,3.60,3.70,3.80,3.90,4,4.10])\n",
    "plt.ylabel(\"Response Time\")\n",
    "plt.xlabel(\"lambda\")\n",
    "plt.title(\"Response time VS Task arrrival rate\")\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig('G:/THESIS/Figuress/c5fig1.png')\n",
    "#plt.figure(figsize=(4,2))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8,8)\n",
    "\n",
    "plt.bar(['FOG1'],[avg_response_time[15]], color = ['red'],label='Q-learning')\n",
    "plt.bar(['FOG1 '],[avg_response_time2[15]], color = ['blue'],label='Actor-Critic')\n",
    "plt.bar(['FOG2'],[avg_response_time[16]], color = ['red'])\n",
    "plt.bar(['FOG2 '],[avg_response_time2[16]], color = ['blue'])\n",
    "plt.bar(['FOG3'],[avg_response_time[17]], color = ['red'])\n",
    "plt.bar(['FOG3 '],[avg_response_time2[17]], color = ['blue'])\n",
    "\n",
    "# plt.bar(['FOG1'],[avg_response_time[18]], color = ['red'],label='Random')\n",
    "# plt.bar(['FOG1 '],[avg_response_time2[18]], color = ['blue'],label='Q-learning')\n",
    "# plt.bar(['FOG2'],[avg_response_time[19]], color = ['red'])\n",
    "# plt.bar(['FOG2 '],[avg_response_time2[19]], color = ['blue'])\n",
    "# plt.bar(['FOG3'],[avg_response_time[20]], color = ['red'])\n",
    "# plt.bar(['FOG3 '],[avg_response_time2[20]], color = ['blue'])\n",
    "\n",
    "# plt.bar(['FOG1'],[avg_response_time[21]], color = ['red'],label='Random')\n",
    "# plt.bar(['FOG1 '],[avg_response_time2[21]], color = ['blue'],label='Q-learning')\n",
    "# plt.bar(['FOG2'],[avg_response_time[22]], color = ['red'])\n",
    "# plt.bar(['FOG2 '],[avg_response_time2[22]], color = ['blue'])\n",
    "# plt.bar(['FOG3'],[avg_response_time[23]], color = ['red'])\n",
    "# plt.bar(['FOG3 '],[avg_response_time2[23]], color = ['blue'])\n",
    "\n",
    "\n",
    "\n",
    "#plt.yticks([0,0.25,0.5,0.75,1,1.25,1.5,1.75,2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.25,4.5])\n",
    "#plt.yticks([0,1,2,3,4,5,6])\n",
    "#plt.yticks([1,1.10,1.20,1.30,1.40,1.50,1.60,1.70,1.80,1.90,2,2.10,2.20,2.30,2.40,2.50,2.60,2.70,2.80,2.90,3,3.10,3.20,3.30,3.40,3.50,3.60,3.70,3.80,3.90,4,4.10])\n",
    "plt.ylabel(\"Response Time\")\n",
    "plt.title(\"Individual fog response time\")\n",
    "plt.legend()\n",
    "#plt.savefig('G:/THESIS/Figuress/c5fig2.png')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hL1gn468ku6G",
    "outputId": "02b942d1-e9fa-480b-a0ea-8f1493b83fa9"
   },
   "outputs": [],
   "source": [
    "[1.564, 4.243, 4.675, 4.766, 4.891, 4.89, 4.87, 4.906, 4.906, 4.967, 4.941, 5.102, 4.901, 4.939, 4.996, 4.938, 5.003, 4.955, 5.012, 5.044]\n",
    "[1.276, 1.307, 1.362, 1.47, 1.683, 2.092, 2.623, 3.222, 3.667, 4.114, 4.298, 4.559, 4.548, 4.531, 4.564, 4.616, 4.612, 4.682, 4.735, 4.531]\n",
    "Image('G:/THESIS/Figuress/c2fig1.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sjq2yCONku6H",
    "outputId": "a8fc8b82-a3c0-4d6d-92c1-377ab9904657"
   },
   "outputs": [],
   "source": [
    "\n",
    "Image('G:/THESIS/Figuress/c2fig2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ZPL9PZ-ku6H",
    "outputId": "ed83944f-ad56-4ba4-c859-d1461af1cc2a"
   },
   "outputs": [],
   "source": [
    "Image('G:/THESIS/Figuress/c3fig1.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0n7ltJWZku6H",
    "outputId": "06317f2b-3d46-4563-9044-b17220eac5c9"
   },
   "outputs": [],
   "source": [
    "Image('G:/THESIS/Figuress/c3fig2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oy3SCA5Rku6H",
    "outputId": "bf5b7d6d-4671-4762-a0a4-2729a22d5ebc"
   },
   "outputs": [],
   "source": [
    "Image('G:/THESIS/Figuress/c4fig1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yyowblYTku6H",
    "outputId": "0b4a74c0-cc25-4400-d797-f7303d3cc1cd"
   },
   "outputs": [],
   "source": [
    "Image('G:/THESIS/Figuress/c4fig2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xkym_hgwku6H",
    "outputId": "73c8ddfe-189e-490a-a5fd-71bd5883b329"
   },
   "outputs": [],
   "source": [
    "Image('G:/THESIS/Figuress/c5fig1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g4JUIE8rku6H",
    "outputId": "ada39ef7-2b3f-48bc-f3ad-85d5d12db4d5"
   },
   "outputs": [],
   "source": [
    "Image('G:/THESIS/Figuress/c5fig2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RvA5c4F-ku6I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5PBkhJDku6I"
   },
   "outputs": [],
   "source": [
    "env1 = simpy.Environment()    \n",
    "server1 = simpy.Resource(env1, capacity=5)\n",
    "server2 = simpy.Resource(env1, capacity=5)\n",
    "server3 = simpy.Resource(env1, capacity=5)\n",
    "rd.seed(2)\n",
    "\n",
    "pipe1 = simpy.Store(env1)\n",
    "pipe2 = simpy.Store(env1)\n",
    "pipe3 = simpy.Store(env1)\n",
    "pipe4 = simpy.Store(env1)\n",
    "pipe5 = simpy.Store(env1)\n",
    "statepipe = simpy.Store(env1)\n",
    "currentpipe = simpy.Store(env1)\n",
    "\n",
    "ms1=mobile(1)\n",
    "ms2=mobile(2)\n",
    "ms3=mobile(3)\n",
    "ms4=mobile(4)\n",
    "\n",
    "fog1 = Fog(0)\n",
    "fog2 = Fog(1)\n",
    "fog3=Fog(2)\n",
    "\n",
    "fog1.Neighbour(fog2,fog3)\n",
    "fog2.Neighbour(fog1,fog3)\n",
    "fog3.Neighbour(fog1,fog2)\n",
    "\n",
    "\n",
    "obj=Decision(1)\n",
    "for i in range(N):\n",
    "    env1.process(obj.decision1(env1,10,server1,server2,server3,pipe1,pipe2,pipe3,pipe4,pipe5,ms1,ms2,ms3,ms4,fog1,fog2,fog3,i,statepipe,currentpipe))\n",
    "env1.run()\n",
    "\n",
    "#print(\"after simulation q_table\",q_table)\n",
    "#print(\"after simulation present state and action\",action_list)\n",
    "\n",
    "fog1_count=obj.fog1_count\n",
    "fog2_count=obj.fog2_count\n",
    "fog3_count=obj.fog3_count\n",
    "fog1_count=fog1_count-fog1.lost\n",
    "fog2_count=fog2_count-fog2.lost\n",
    "fog3_count=fog3_count-fog3.lost\n",
    "\n",
    "print(\"lost\",fog1.lost,fog2.lost,fog3.lost)\n",
    "print(\"present count\",fog1_count,fog2_count,fog3_count)\n",
    "avgwaittime=sum(fog1.waitlist)/fog1_count\n",
    "print(\"FOG-1 Average queueing time:\", avgwaittime)\n",
    "avgservicetime=sum(fog1.service_time)/fog1_count\n",
    "print(\"FOG-1 Average service time:\", avgservicetime)\n",
    "avgsystemtime11=sum(fog1.response_time_list)/fog1_count\n",
    "print(\"FOG-1 Average response time:\", avgsystemtime)\n",
    "avgenergy11=sum(fog1.energy_offloading)/fog1_count\n",
    "print(\"FOG-1 Average Energy consumption:\", avgenergy)\n",
    "#print(\"No    response_time       reward\")\n",
    "#i=0\n",
    "#while (i<N):\n",
    "#   print(\"{}     {}     {}\".format(i+1,fog2.response_time_list[i],fog2.reward_list[i]))\n",
    "#  i+=1\n",
    "#print(\"FOG-2 MAXIMUM REAWARD:\", max(fog2.reward_list))\n",
    "#print(\"FOG-2 total number of task in queue\",fog2.Number_queue)\n",
    "avgwaittime=sum(fog2.waitlist)/fog2_count\n",
    "print(\"FOG-2 Average queueing time:\", avgwaittime)\n",
    "avgservicetime=sum(fog2.service_time)/fog2_count\n",
    "print(\"FOG-2 Average service time:\", avgservicetime)\n",
    "avgsystemtime22=sum(fog2.response_time_list)/fog2_count\n",
    "print(\"FOG-2 Average response time:\", avgsystemtime)\n",
    "avgenergy22=sum(fog2.energy_offloading)/fog2_count\n",
    "print(\"FOG-2 Average Energy consumption:\", avgenergy)\n",
    "\n",
    "avgwaittime=sum(fog3.waitlist)/fog3_count\n",
    "print(\"FOG-3 Average queueing time:\", avgwaittime)\n",
    "avgservicetime=sum(fog3.service_time)/fog3_count\n",
    "print(\"FOG-3 Average service time:\", avgservicetime)\n",
    "avgsystemtime33=sum(fog3.response_time_list)/fog3_count\n",
    "print(\"FOG-3 Average response time:\", avgsystemtime)\n",
    "avgenergy33=sum(fog3.energy_offloading)/fog3_count\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNaKq9_Zku6I"
   },
   "outputs": [],
   "source": [
    "with open('Actor-Critic-lr-0.000025-N-15000.txt', 'w') as fl:\n",
    "    for item in rrt2:\n",
    "        fl.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JdiW68KEku6I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wqQJZC7nku6I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Q _learning_(Final_Version_Plotting graph 4  parameter) -each mobile.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
